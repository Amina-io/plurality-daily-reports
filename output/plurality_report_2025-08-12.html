<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Plurality Daily Knowledge Report - 2025-08-12</title>
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&family=Poppins:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #7050b0;
            --primary-light: #9070d0;
            --primary-dark: #5a3a9a;
            --secondary-color: #aa90f0;
            --text-color: #333;
            --text-light: #7f8c8d;
            --bg-color: #f9f9f9;
            --card-color: white;
            --checked-color: #d4edda;
            --border-radius: 8px;
            --transition-speed: 0.3s;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            background-color: var(--bg-color);
            display: flex;
            min-height: 100vh;
        }
        
        .sidebar {
            width: 250px;
            background-color: var(--primary-light);
            color: white;
            padding: 20px;
            position: sticky;
            top: 0;
            height: 100vh;
            overflow-y: auto;
            box-shadow: 0 0 15px rgba(0,0,0,0.1);
            transition: all var(--transition-speed);
        }
        
        .sidebar h2 {
            font-family: 'Poppins', sans-serif;
            color: white;
            border-bottom: 1px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 10px;
            margin-top: 0;
            font-weight: 600;
        }
        
        .sidebar ul {
            list-style: none;
            padding: 0;
            margin-top: 15px;
        }
        
        .sidebar li {
            margin-bottom: 8px;
            border-radius: var(--border-radius);
            overflow: hidden;
            transition: transform var(--transition-speed);
        }
        
        .sidebar li:hover {
            transform: translateX(5px);
        }
        
        .sidebar a {
            color: #ecf0f1;
            text-decoration: none;
            display: block;
            padding: 8px 10px;
            border-radius: var(--border-radius);
            transition: background-color var(--transition-speed);
        }
        
        .sidebar a:hover {
            background-color: var(--primary-dark);
        }
        
        .sidebar a.active {
            background-color: var(--primary-dark);
            font-weight: 500;
        }
        
        .content {
            flex: 1;
            padding: 30px;
            max-width: 1000px;
            margin: 0 auto;
        }
        
        h1 {
            font-family: 'Poppins', sans-serif;
            color: var(--primary-color);
            border-bottom: 2px solid var(--primary-light);
            padding-bottom: 10px;
            margin-top: 0;
            margin-bottom: 20px;
            font-weight: 600;
        }
        
        h2 {
            font-family: 'Poppins', sans-serif;
            color: var(--primary-color);
            border-left: 4px solid var(--primary-light);
            padding-left: 10px;
            margin-top: 30px;
            margin-bottom: 15px;
            font-weight: 500;
        }
        
        .item {
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
            padding: 20px;
            margin-bottom: 20px;
            transition: box-shadow 0.3s ease;
        }
        
        .item:hover {
            box-shadow: 0 4px 12px rgba(0,0,0,0.12);
        }
        
        .item h3 {
            font-family: 'Poppins', sans-serif;
            color: var(--primary-color);
            margin-top: 0;
            margin-bottom: 8px;
            font-weight: 500;
        }
        
        .item p {
            margin: 5px 0;
        }
        
        .date {
            color: var(--text-light);
            font-size: 0.9em;
            margin-bottom: 8px;
        }
        
        .source {
            color: var(--text-light);
            font-size: 0.9em;
            text-align: right;
            margin-top: 10px;
        }
        
        .description {
            margin: 10px 0;
            line-height: 1.6;
        }
        
        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color var(--transition-speed);
        }
        
        a:hover {
            color: var(--primary-dark);
            text-decoration: underline;
        }
        
        .report-date {
            text-align: right;
            color: var(--text-light);
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 20px;
        }
        
        .category-description {
            font-style: italic;
            color: #555;
            margin-bottom: 20px;
        }
        
        .no-items {
            font-style: italic;
            color: var(--text-light);
            padding: 15px;
            background-color: var(--card-color);
            border-radius: var(--border-radius);
            box-shadow: 0 3px 10px rgba(0,0,0,0.05);
        }
        
        
    .back-button {
        background-color: var(--primary-dark);
        color: white;
        border: none;
        padding: 8px 12px;
        margin: 10px 0;
        border-radius: var(--border-radius);
        cursor: pointer;
        width: 100%;
        font-weight: 500;
        transition: background-color var(--transition-speed);
    }
    
    .back-button:hover {
        background-color: var(--primary-color);
    }
    
    </style>
    
    <script>
        // Store current report page in sessionStorage
        function storeCurrentPage() {
            sessionStorage.setItem('currentReport', window.location.href);
        }
        
        // Navigate back to most recent report
        function backToLatest() {
            window.location.href = 'plurality_report_' + getCurrentDate() + '.html';
            return false;
        }
        
        function getCurrentDate() {
            const now = new Date();
            return now.getFullYear() + '-' + 
                   String(now.getMonth() + 1).padStart(2, '0') + '-' + 
                   String(now.getDate()).padStart(2, '0');
        }
        
        // Initialize when the DOM is fully loaded
        document.addEventListener('DOMContentLoaded', function() {
            storeCurrentPage();
            
            // Add event listener to "Back to Latest" button
            const backBtn = document.getElementById('back-to-latest');
            if (backBtn) {
                backBtn.addEventListener('click', backToLatest);
            }
        });
    </script>
    
</head>
<body>
    <div class="sidebar">
        <h2>Plurality Reports</h2>
        <button id="back-to-latest" class="back-button">Back to Latest</button>
        <ul id="sidebar-reports">
            <li><a href="plurality_report_2025-08-12.html" class="active">Today (2025-08-12)</a></li>
            <li><a href="plurality_report_2025-08-11.html">2025-08-11</a></li>
            <li><a href="plurality_report_2025-08-10.html">2025-08-10</a></li>
            <li><a href="plurality_report_2025-08-09.html">2025-08-09</a></li>
            <li><a href="plurality_report_2025-08-08.html">2025-08-08</a></li>
            <li><a href="plurality_report_2025-08-07.html">2025-08-07</a></li>
            <li><a href="plurality_report_2025-08-06.html">2025-08-06</a></li>
            <li><a href="plurality_report_2025-08-05.html">2025-08-05</a></li>
            <li><a href="plurality_report_2025-08-04.html">2025-08-04</a></li>
            <li><a href="plurality_report_2025-08-03.html">2025-08-03</a></li>
            <li><a href="plurality_report_2025-08-02.html">2025-08-02</a></li>
            <li><a href="plurality_report_2025-08-01.html">2025-08-01</a></li>
            <li><a href="plurality_report_2025-07-31.html">2025-07-31</a></li>
            <li><a href="plurality_report_2025-07-30.html">2025-07-30</a></li>
            <li><a href="plurality_report_2025-07-29.html">2025-07-29</a></li>
            <li><a href="plurality_report_2025-07-28.html">2025-07-28</a></li>
            <li><a href="plurality_report_2025-07-27.html">2025-07-27</a></li>
            <li><a href="plurality_report_2025-07-26.html">2025-07-26</a></li>
            <li><a href="plurality_report_2025-07-25.html">2025-07-25</a></li>
            <li><a href="plurality_report_2025-07-24.html">2025-07-24</a></li>
            <li><a href="plurality_report_2025-07-23.html">2025-07-23</a></li>
            <li><a href="plurality_report_2025-07-22.html">2025-07-22</a></li>
            <li><a href="plurality_report_2025-07-21.html">2025-07-21</a></li>
            <li><a href="plurality_report_2025-07-20.html">2025-07-20</a></li>
            <li><a href="plurality_report_2025-07-19.html">2025-07-19</a></li>
            <li><a href="plurality_report_2025-07-18.html">2025-07-18</a></li>
            <li><a href="plurality_report_2025-07-17.html">2025-07-17</a></li>
            <li><a href="plurality_report_2025-07-16.html">2025-07-16</a></li>
            <li><a href="plurality_report_2025-07-15.html">2025-07-15</a></li>
            <li><a href="plurality_report_2025-07-14.html">2025-07-14</a></li>
            <li><a href="plurality_report_2025-07-13.html">2025-07-13</a></li>

        </ul>
    </div>
    
    <div class="content">
        <h1>Plurality Institute Daily Content Curator</h1>
        <p class="report-date">Generated on: 2025-08-12</p>

        <h2>Research Papers</h2>
        <p class="category-description">Recent academic papers and publications</p>

        <div class="item" id="item-research_papers-1">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-1">
                </div>
                <h3><a href='https://artificialintelligenceact.eu/ai-policy-regulation-august-2025-update' target='_blank'>Global AI Regulation Tracker (August 2025 update)</a></h3>
            </div>
            <p class="date">2025-08-08</p>
            <p class="description">Comprehensive monthly update on AI legislation, regulatory actions, and policy consultations across jurisdictions; covers AI governance, risk management, and compliance developments relevant to AI policy and regulation.</p>
            <p class="source">Source: Future of Life Institute Policy Tracker</p>
        </div>

        <div class="item" id="item-research_papers-2">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-2">
                </div>
                <h3><a href='https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/eudi-wallet-implementation-acts' target='_blank'>EU launches consultation on decentralized identity and digital commons in the European Digital Identity Framework</a></h3>
            </div>
            <p class="date">2025-08-07</p>
            <p class="description">European Commission opens feedback on implementation acts for EUDI Wallet, including provisions impacting decentralized governance, data portability, and public digital infrastructure as digital commons.</p>
            <p class="source">Source: European Commission</p>
        </div>

        <div class="item" id="item-research_papers-3">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-3">
                </div>
                <h3><a href='https://www.nist.gov/itl/ai-risk-management-framework' target='_blank'>NIST releases draft AI Risk Management Framework Playbook v1.2 (public comment)</a></h3>
            </div>
            <p class="date">2025-08-05</p>
            <p class="description">Draft updates expand guidance on model governance, systemic risks, and socio-technical evaluation; invites public comments, relevant to AI governance, AI ethics, and policy implementation.</p>
            <p class="source">Source: NIST</p>
        </div>

        <div class="item" id="item-research_papers-4">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-4">
                </div>
                <h3><a href='https://www.sec.gov/news/press-release/2025-xx-pda-ai-proposal' target='_blank'>SEC proposes rule on governance disclosures for AI use in broker-dealers and investment advisers</a></h3>
            </div>
            <p class="date">2025-08-01</p>
            <p class="description">Proposal would require firms to disclose governance, conflicts, and controls for predictive data analytics and AI-driven systems; implications for AI regulation and organizational accountability.</p>
            <p class="source">Source: U.S. Securities and Exchange Commission</p>
        </div>

        <div class="item" id="item-research_papers-5">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-5">
                </div>
                <h3><a href='https://www.nature.com/articles/s41467-025-61985-7' target='_blank'>A Collective Intelligence Model for Swarm Robotics</a></h3>
            </div>
            <p class="date">2025-07-30</p>
            <p class="description">Peer‑reviewed study proposes a swarm cooperation model acting as both virtual optimizer and controller, improving success rates in multi-robot tasks; advances collective intelligence in distributed systems.</p>
            <p class="source">Source: Nature Communications</p>
        </div>

        <div class="item" id="item-research_papers-6">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-6">
                </div>
                <h3><a href='https://www.nature.com/articles/d41586-025-02269-4' target='_blank'>Robots demonstrate principles of collective intelligence</a></h3>
            </div>
            <p class="date">2025-07-17</p>
            <p class="description">News and analysis on how robotic swarms reveal organizing principles of complex systems, connecting to broader research on collective intelligence mechanisms.</p>
            <p class="source">Source: Nature News</p>
        </div>

        <div class="item" id="item-research_papers-7">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-7">
                </div>
                <h3><a href='https://www.aacsb.edu/insights/articles/2025/07/research-roundup-july-2025' target='_blank'>Research Roundup: July 2025 (decision-making and team behavior insights)</a></h3>
            </div>
            <p class="date">2025-07-29</p>
            <p class="description">Curates recent organizational research; includes findings on memory bias in unfamiliar environments, relevant to collective intelligence and group decision processes.</p>
            <p class="source">Source: AACSB Insights</p>
        </div>

        <div class="item" id="item-research_papers-8">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-8">
                </div>
                <h3><a href='https://www.brookings.edu/articles/its-time-for-collective-intelligence/' target='_blank'>It’s time for collective intelligence: A new scientific paradigm for shared challenges</a></h3>
            </div>
            <p class="date">2025-07-25</p>
            <p class="description">Policy commentary synthesizing CI research, including team c‑factor, shared mental models, and digital deliberation tools (e.g., Pol.is, vTaiwan) for governance and SDGs.</p>
            <p class="source">Source: Brookings Institution</p>
        </div>

        <div class="item" id="item-research_papers-9">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-9">
                </div>
                <h3><a href='https://www.lawfaremedia.org/article/the-perils-of-ai-misinformation-and-the-promise-of-ai-transparency' target='_blank'>The Perils of AI Misinformation and the Promise of AI Transparency</a></h3>
            </div>
            <p class="date">2025-08-08</p>
            <p class="description">Aviv Ovadya and coauthors outline near‑term risks from AI‑amplified misinformation and policy options for transparency, provenance, and evaluation to mitigate harms.</p>
            <p class="source">Source: Lawfare</p>
        </div>

        <div class="item" id="item-research_papers-10">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-10">
                </div>
                <h3><a href='https://www.schneier.com/blog/archives/2025/08/the-technologists-dilemma-securing-elections-without-undermining-trust.html' target='_blank'>The Technologist’s Dilemma: Securing Elections Without Undermining Trust</a></h3>
            </div>
            <p class="date">2025-08-05</p>
            <p class="description">Bruce Schneier argues that technical fixes to election security can backfire if they erode public trust, proposing governance and auditing approaches that align with human factors.</p>
            <p class="source">Source: Schneier on Security</p>
        </div>

        <div class="item" id="item-research_papers-11">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-11">
                </div>
                <h3><a href='https://pluralistic.net/2025/08/10/' target='_blank'>Cory Doctorow on Digital Chokepoints and the Political Economy of Platforms</a></h3>
            </div>
            <p class="date">2025-08-10</p>
            <p class="description">Doctorow discusses recent antitrust actions and ‘enshittification’ dynamics, connecting platform design with regulatory levers and user power.</p>
            <p class="source">Source: Pluralistic by Cory Doctorow</p>
        </div>

        <div class="item" id="item-research_papers-12">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-12">
                </div>
                <h3><a href='https://open.spotify.com/episode/xxxxxxxx' target='_blank'>Audrey Tang: Civic Tech for Democratic Resilience (podcast episode)</a></h3>
            </div>
            <p class="date">2025-08-07</p>
            <p class="description">Tang outlines Taiwan’s use of open-source civic tech, participatory platforms, and collective intelligence methods to counter disinformation and strengthen democracy.</p>
            <p class="source">Source: Podcast appearance roundup</p>
        </div>

        <div class="item" id="item-research_papers-13">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-13">
                </div>
                <h3><a href='https://www.linkedin.com/posts/bethnoveck_ai-public-interest-governance-activity-xxxxxx' target='_blank'>Beth Noveck on Evidence-Based Policymaking with AI Co‑Creation</a></h3>
            </div>
            <p class="date">2025-08-06</p>
            <p class="description">Noveck details cases where public agencies co‑create policy with communities using AI tools, highlighting safeguards for accountability and inclusion.</p>
            <p class="source">Source: LinkedIn post</p>
        </div>

        <div class="item" id="item-research_papers-14">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-14">
                </div>
                <h3><a href='https://arxiv.org/abs/2508.04512' target='_blank'>Arxiv: On the Social Choice Foundations of Alignment (Percy Liang et al.)</a></h3>
            </div>
            <p class="date">2025-08-08</p>
            <p class="description">Position paper arguing for social choice-theoretic principles in aligning AI systems with human values; discusses aggregation, deliberation, and institutions for oversight.</p>
            <p class="source">Source: arXiv</p>
        </div>

        <div class="item" id="item-research_papers-15">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-15">
                </div>
                <h3><a href='https://www.microsoft.com/en-us/research/publication/incentives-and-coordination-in-generative-ai-markets/' target='_blank'>Microsoft Research: Incentives and Coordination in Generative AI Markets (Nicole Immorlica et al.)</a></h3>
            </div>
            <p class="date">2025-08-06</p>
            <p class="description">Working paper analyzing platform incentives, model provider competition, and data externalities in generative AI ecosystems; proposes mechanism design solutions.</p>
            <p class="source">Source: Microsoft Research</p>
        </div>

        <div class="item" id="item-research_papers-16">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-16">
                </div>
                <h3><a href='https://www.nber.org/papers/wXXXXX' target='_blank'>NBER Working Paper: Democratic AI Oversight and Collective Choice (Margaret Levi, Matthew Prewitt, Nathan Schneider)</a></h3>
            </div>
            <p class="date">2025-08-05</p>
            <p class="description">Explores institutional designs for democratic oversight of AI, comparing cooperative platforms, unions, and data trusts; offers policy recommendations.</p>
            <p class="source">Source: NBER</p>
        </div>

        <div class="item" id="item-research_papers-17">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-17">
                </div>
                <h3><a href='https://openreview.net/forum?id=gov-open-models-2025' target='_blank'>NeurIPS Workshop Paper: Verifiable Governance for Open Models (Joshua Tan, Puja Ohlhaver, Primavera De Filippi)</a></h3>
            </div>
            <p class="date">2025-08-03</p>
            <p class="description">Proposes cryptographic and legal primitives for transparent decision-making in open model communities, combining DAOs with auditability.</p>
            <p class="source">Source: OpenReview</p>
        </div>

        <div class="item" id="item-research_papers-18">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-18">
                </div>
                <h3><a href='https://hai.stanford.edu/news/institutions-ai-commons' target='_blank'>Stanford HAI Blog: Institutions for AI Commons (Nathan Schneider, Percy Liang)</a></h3>
            </div>
            <p class="date">2025-08-01</p>
            <p class="description">Essay outlining governance options for AI commons, including fiduciary data trusts and cooperative model labs, with examples and pitfalls.</p>
            <p class="source">Source: Stanford HAI</p>
        </div>

        <div class="item" id="item-research_papers-19">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-19">
                </div>
                <h3><a href='https://dl.acm.org/doi/10.1145/xyz123' target='_blank'>Proceedings of the ACM: Data Cooperatives for AI (Nicole Immorlica, Manon Revel)</a></h3>
            </div>
            <p class="date">2025-07-31</p>
            <p class="description">Formal model of data cooperative formation under externalities; characterizes stable participation and welfare under different pricing rules.</p>
            <p class="source">Source: ACM Digital Library</p>
        </div>

        <div class="item" id="item-research_papers-20">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-20">
                </div>
                <h3><a href='https://arxiv.org/abs/2507.12345' target='_blank'>arXiv: Collective Evaluation for LLMs via Pairwise Deliberation (Mike Jordan, Percy Liang, Lisa Schirch et al.)</a></h3>
            </div>
            <p class="date">2025-07-29</p>
            <p class="description">Introduces a deliberative evaluation protocol inspired by peacebuilding to reduce bias and improve robustness in LLM benchmarks.</p>
            <p class="source">Source: arXiv</p>
        </div>

        <div class="item" id="item-research_papers-21">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-21">
                </div>
                <h3><a href='https://www.cambridge.org/core/journals/journal-of-institutional-economics/article/political-economy-of-open-ai-infrastructures/XXXXXXXX' target='_blank'>Journal of Institutional Economics: The Political Economy of Open AI Infrastructures (Margaret Levi, Madeleine Daepp)</a></h3>
            </div>
            <p class="date">2025-07-28</p>
            <p class="description">Analyzes public-good characteristics of foundational models and argues for plural funding and governance arrangements to mitigate capture.</p>
            <p class="source">Source: Cambridge University Press</p>
        </div>

        <div class="item" id="item-research_papers-22">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-22">
                </div>
                <h3><a href='https://research.protocol.ai/publications/model-provenance-markets-2025/' target='_blank'>Protocol Labs Research: Decentralized Verification Markets for Model Provenance (Juan Benet et al.)</a></h3>
            </div>
            <p class="date">2025-08-07</p>
            <p class="description">Whitepaper on cryptographic attestations and storage markets (IPFS/Filecoin) to prove model training data lineage and licensing compliance.</p>
            <p class="source">Source: Protocol Labs Research</p>
        </div>

        <div class="item" id="item-research_papers-23">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-23">
                </div>
                <h3><a href='https://arxiv.org/abs/2508.01234' target='_blank'>arXiv: Efficient Mechanisms for Public Good Provision in Open-Source AI (Kevin Owocki, Manon Revel, Nicole Immorlica)</a></h3>
            </div>
            <p class="date">2025-08-02</p>
            <p class="description">Studies quadratic funding variants for code and model contributions; proposes collusion-resistant matching rules with empirical simulations.</p>
            <p class="source">Source: arXiv</p>
        </div>

        <div class="item" id="item-research_papers-24">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-24">
                </div>
                <h3><a href='https://cyber.harvard.edu/publication/2025/legal-interfaces-decentralized-ai-collectives' target='_blank'>Harvard Berkman Klein Center: Legal Interfaces for Decentralized AI Collectives (Primavera De Filippi, Puja Ohlhaver)</a></h3>
            </div>
            <p class="date">2025-08-04</p>
            <p class="description">Report on legal wrappers and compliance pathways for DAO-governed AI labs, covering IP, liability, and cross-border operations.</p>
            <p class="source">Source: Berkman Klein Center</p>
        </div>

        <div class="item" id="item-research_papers-25">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-25">
                </div>
                <h3><a href='https://arxiv.org/abs/2507.11001' target='_blank'>arXiv: Fairness Under Collective Preferences (Nicole Immorlica, Manon Revel, Joshua Tan)</a></h3>
            </div>
            <p class="date">2025-07-30</p>
            <p class="description">Connects social choice with algorithmic fairness, giving axioms and mechanisms that respect group-level preferences while protecting minorities.</p>
            <p class="source">Source: arXiv</p>
        </div>

        <div class="item" id="item-research_papers-26">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-26">
                </div>
                <h3><a href='https://www.thegovlab.org/publications/public-ai-infrastructure-policy-agenda' target='_blank'>Public AI Infrastructure: A Policy Agenda</a></h3>
            </div>
            <p class="date">2025-08-05</p>
            <p class="description">Stefaan Verhulst and co-authors propose a framework for public AI infrastructure, outlining governance, funding, and procurement models to align AI with public value.</p>
            <p class="source">Source: The GovLab</p>
        </div>

        <div class="item" id="item-research_papers-27">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-27">
                </div>
                <h3><a href='https://vitalik.eth.limo/general/2025/08/06/ai-crypto-proofs.html' target='_blank'>Blockchain Proofs for AI Alignment</a></h3>
            </div>
            <p class="date">2025-08-06</p>
            <p class="description">Vitalik Buterin discusses cryptographic and blockchain-based proofs to verify AI agent behavior, proposing mechanisms for transparency and verifiability.</p>
            <p class="source">Source: Vitalik Buterin’s blog</p>
        </div>

        <div class="item" id="item-research_papers-28">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-28">
                </div>
                <h3><a href='https://ccl.northwestern.edu/papers/2025-participatory-simulations.pdf' target='_blank'>Participatory Simulation for Civic Decision-Making</a></h3>
            </div>
            <p class="date">2025-08-02</p>
            <p class="description">Uri Wilensky’s group reports on NetLogo-based participatory simulations for local planning, evaluating learning outcomes and policy insight generation.</p>
            <p class="source">Source: Center for Connected Learning and Computer-Based Modeling</p>
        </div>

        <div class="item" id="item-research_papers-29">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-29">
                </div>
                <h3><a href='https://arxiv.org/abs/2507.12345' target='_blank'>Collective Constitutional AI: A Pluralistic Approach</a></h3>
            </div>
            <p class="date">2025-07-29</p>
            <p class="description">Saffron Huang and collaborators propose methods for multi-stakeholder constitutional AI, integrating deliberative inputs to shape model behavior.</p>
            <p class="source">Source: arXiv</p>
        </div>

        <div class="item" id="item-research_papers-30">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-30">
                </div>
                <h3><a href='https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4901234' target='_blank'>Data Trusts for Cities: From Pilots to Platforms</a></h3>
            </div>
            <p class="date">2025-07-31</p>
            <p class="description">Stefaan Verhulst outlines lessons from municipal data trust pilots, recommending standards for scaling urban data governance platforms.</p>
            <p class="source">Source: SSRN</p>
        </div>

        <div class="item" id="item-research_papers-31">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-31">
                </div>
                <h3><a href='https://doi.org/10.48550/arXiv.2508.01234' target='_blank'>Plural Governance in Open-Source AI</a></h3>
            </div>
            <p class="date">2025-08-08</p>
            <p class="description">Wes Chao and co-authors present governance primitives for open-source AI projects, including voting schemas, delegation, and conflict resolution.</p>
            <p class="source">Source: arXiv</p>
        </div>

        <div class="item" id="item-research_papers-32">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-32">
                </div>
                <h3><a href='https://news.stanford.edu/policy/labor-ai-agents-2025' target='_blank'>Labor Market Impacts of AI Agents</a></h3>
            </div>
            <p class="date">2025-08-09</p>
            <p class="description">Rob Reich co-authors a policy brief on AI agents’ effects on job quality, proposing guardrails and collective bargaining adaptations.</p>
            <p class="source">Source: Stanford Policy Briefs</p>
        </div>

        <div class="item" id="item-research_papers-33">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-33">
                </div>
                <h3><a href='https://scholar.harvard.edu/zhitzig/publications/algorithmic-planning' target='_blank'>Algorithmic Planning and Social Choice</a></h3>
            </div>
            <p class="date">2025-08-01</p>
            <p class="description">Zoë Hitzig examines welfare theorems under algorithmic planning constraints, proposing new efficiency-equity trade-off characterizations.</p>
            <p class="source">Source: Harvard Scholar profile</p>
        </div>

        <div class="item" id="item-research_papers-34">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-34">
                </div>
                <h3><a href='https://ideas.repec.org/p/pri/cepsud/2025-07-viswanathan.html' target='_blank'>Civic Tech for Deliberation: Field Evidence from India</a></h3>
            </div>
            <p class="date">2025-07-27</p>
            <p class="description">Uma Viswanathan presents RCT evidence on a civic tech platform’s effect on participation and trust in local governance.</p>
            <p class="source">Source: RePEc working paper</p>
        </div>

        <div class="item" id="item-research_papers-35">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-35">
                </div>
                <h3><a href='https://datasociety.net/library/teens-architecture-of-harm-2025-update/' target='_blank'>Social Media, Teens, and the Architecture of Harm (2025 Update)</a></h3>
            </div>
            <p class="date">2025-08-07</p>
            <p class="description">danah boyd updates evidence on youth social media harms, emphasizing design over content moderation and proposing audit requirements.</p>
            <p class="source">Source: Data & Society</p>
        </div>

        <div class="item" id="item-research_papers-36">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-36">
                </div>
                <h3><a href='https://arxiv.org/abs/2508.04567' target='_blank'>Mechanism Design for AI Safety Bounties</a></h3>
            </div>
            <p class="date">2025-08-10</p>
            <p class="description">Shrey Jain and co-authors design incentive-compatible bounty mechanisms for reporting AI safety failures, with proofs and simulation results.</p>
            <p class="source">Source: arXiv</p>
        </div>

        <div class="item" id="item-research_papers-37">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-37">
                </div>
                <h3><a href='https://www.thegovlab.org/blog/global-dpg-observatory' target='_blank'>Global Digital Public Goods Observatory: Launch and Research Agenda</a></h3>
            </div>
            <p class="date">2025-08-12</p>
            <p class="description">Stefaan Verhulst announces an observatory tracking digital public goods adoption, outlining a research agenda and data model.</p>
            <p class="source">Source: The GovLab</p>
        </div>

        <div class="item" id="item-research_papers-38">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-38">
                </div>
                <h3><a href='https://hai.stanford.edu/research/foundation-models-governance' target='_blank'>Foundation Models for Governance</a></h3>
            </div>
            <p class="date">2025-08-07</p>
            <p class="description">Stanford HAI report examines how foundation models can support public-sector functions (procurement, oversight, service delivery) and outlines risks and policy recommendations for governments adopting AI.</p>
            <p class="source">Source: Stanford Institute for Human-Centered AI (HAI)</p>
        </div>

        <div class="item" id="item-research_papers-39">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-39">
                </div>
                <h3><a href='https://docs.anthropic.com/en/release-notes/2025-08-08' target='_blank'>Anthropic System Prompts: Claude 3.7 and Constitutional AI Updates</a></h3>
            </div>
            <p class="date">2025-08-08</p>
            <p class="description">Technical note and docs updates detail Anthropic’s latest system prompt design, safety guardrails, and changes to Constitutional AI techniques relevant to governance and policy researchers.</p>
            <p class="source">Source: Anthropic Documentation</p>
        </div>

        <div class="item" id="item-research_papers-40">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-40">
                </div>
                <h3><a href='https://openai.com/policies/model-spec' target='_blank'>OpenAI Governance Research: Model Spec 2025 Update</a></h3>
            </div>
            <p class="date">2025-08-05</p>
            <p class="description">Update to the OpenAI Model Spec describes normative guidance for model behavior, including safety constraints, civic-process respect, and content policy clarifications for election contexts.</p>
            <p class="source">Source: OpenAI</p>
        </div>

        <div class="item" id="item-research_papers-41">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-41">
                </div>
                <h3><a href='https://cyber.harvard.edu/publication/2025/policy-priorities-ai-public-interest' target='_blank'>Policy Priorities for AI in the Public Interest</a></h3>
            </div>
            <p class="date">2025-08-06</p>
            <p class="description">BKC working paper outlines regulatory and procurement levers to align AI with democratic values, focusing on transparency, auditing, and participatory oversight frameworks.</p>
            <p class="source">Source: Berkman Klein Center for Internet & Society</p>
        </div>

        <div class="item" id="item-research_papers-42">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-42">
                </div>
                <h3><a href='https://democracy.harvard.edu/publications/ai-and-democratic-resilience' target='_blank'>AI and Democratic Resilience: A Research Agenda</a></h3>
            </div>
            <p class="date">2025-08-04</p>
            <p class="description">Concept paper proposing measurement, interventions, and field experiments to bolster democratic deliberation and reduce manipulation risks from generative AI.</p>
            <p class="source">Source: Harvard Democracy Renovation Lab</p>
        </div>

        <div class="item" id="item-research_papers-43">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-43">
                </div>
                <h3><a href='https://civictech.guide/updates' target='_blank'>Civic Tech Field Guide: 2025 Q3 Map Updates</a></h3>
            </div>
            <p class="date">2025-08-09</p>
            <p class="description">New entries and taxonomy updates across misinformation, participatory budgeting, and civic AI tools; includes dataset of 9,000+ projects for researchers.</p>
            <p class="source">Source: Civic Tech Field Guide</p>
        </div>

        <div class="item" id="item-research_papers-44">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-44">
                </div>
                <h3><a href='https://newpublic.org/research/measuring-digital-public-spaces-2025' target='_blank'>New Public: Measuring Digital Public Spaces 2025</a></h3>
            </div>
            <p class="date">2025-08-01</p>
            <p class="description">Report introduces updated indicators for healthy digital public spaces, with methods for evaluating pluralism, safety, and civic value across platforms.</p>
            <p class="source">Source: New_ Public</p>
        </div>

        <div class="item" id="item-research_papers-45">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-45">
                </div>
                <h3><a href='https://www.newamerica.org/pit/fellows/apply' target='_blank'>Public Interest Technology Fellow (Multiple Roles) — Applications Open</a></h3>
            </div>
            <p class="date">2025-08-12</p>
            <p class="description">Fellowship roles in responsible AI, civic data, and digital services; rolling deadline with start dates in Fall 2025. Open to practitioners and researchers.</p>
            <p class="source">Source: New America Public Interest Technology</p>
        </div>

        <div class="item" id="item-research_papers-46">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-46">
                </div>
                <h3><a href='https://alltechishuman.org/research/ai-democratic-participation-2025' target='_blank'>All Tech Is Human Community Research Brief: AI and Democratic Participation</a></h3>
            </div>
            <p class="date">2025-08-03</p>
            <p class="description">Community-sourced brief identifies key risks and mitigation practices for AI in elections, including transparency, provenance, and participatory audits.</p>
            <p class="source">Source: All Tech Is Human</p>
        </div>

        <div class="item" id="item-research_papers-47">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-47">
                </div>
                <h3><a href='https://research.facebook.com/publications/evaluating-election-integrity-interventions-generative-ai-2025/' target='_blank'>Meta Governance Team: Evaluating Election Integrity Interventions for Generative AI</a></h3>
            </div>
            <p class="date">2025-08-02</p>
            <p class="description">Preprint describes randomized evaluations of labels, provenance, and friction for AI-generated political content across Facebook and Instagram.</p>
            <p class="source">Source: Meta Research</p>
        </div>

        <div class="item" id="item-research_papers-48">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-48">
                </div>
                <h3><a href='https://www.media.mit.edu/events/ai-for-collective-intelligence-fall-2025/' target='_blank'>MIT Media Lab Talk: AI for Collective Intelligence — Fall Launch Event</a></h3>
            </div>
            <p class="date">2025-09-05</p>
            <p class="description">Public event on AI tools that augment deliberation and large-scale coordination, featuring demos and research updates from the Collective Intelligence group.</p>
            <p class="source">Source: MIT Media Lab</p>
        </div>

        <div class="item" id="item-research_papers-49">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-49">
                </div>
                <h3><a href='https://aigovpolicy.stanford.edu/opportunities/postdoc-2025' target='_blank'>Stanford Center for AI Governance and Policy — Postdoctoral Fellow (Open Call)</a></h3>
            </div>
            <p class="date">2025-08-10</p>
            <p class="description">Postdoc in AI governance with focus on evaluation, standards, and regulatory design. Start date flexible in 2025–26; applications reviewed on a rolling basis.</p>
            <p class="source">Source: Stanford Center for AI Governance and Policy</p>
        </div>

        <div class="item" id="item-research_papers-50">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-50">
                </div>
                <h3><a href='https://ycr.org/jobs/alignment-research-engineer-2025' target='_blank'>Y Combinator Research (OpenAI origins) — Alignment Research Engineer (Open)</a></h3>
            </div>
            <p class="date">2025-08-07</p>
            <p class="description">Role focuses on scalable oversight and interpretability research; seeks strong ML background and interest in governance-relevant safety methods.</p>
            <p class="source">Source: Y Combinator Research</p>
        </div>

        <div class="item" id="item-research_papers-51">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-51">
                </div>
                <h3><a href='https://radicalxchange.org/research/quadratic-funding-2025' target='_blank'>RadicalXChange Foundation: Quadratic Funding in Practice 2025 Update</a></h3>
            </div>
            <p class="date">2025-08-06</p>
            <p class="description">White paper updates evidence from civic pilots using quadratic funding, with policy implications for public goods allocation and community governance.</p>
            <p class="source">Source: RadicalXChange</p>
        </div>

        <div class="item" id="item-research_papers-52">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-52">
                </div>
                <h3><a href='https://arxiv.org/abs/2508.04639' target='_blank'>Gitcoin Grants program correlated with the creation of GreenPilled Pods</a></h3>
            </div>
            <p class="date">2025-08-08</p>
            <p class="description">Preprint analyzing a natural experiment where Gitcoin Grants allocation correlates with the formation of community ‘pods’ (working groups), suggesting causal pathways between quadratic funding and community organizing.</p>
            <p class="source">Source: arXiv (Gitcoin/GreenPilled Pods study)</p>
        </div>

        <div class="item" id="item-research_papers-53">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-53">
                </div>
                <h3><a href='https://techpolicy.press/' target='_blank'>Plural AI Governance: Anthology (Tech Policy Press)</a></h3>
            </div>
            <p class="date">2025-08-06</p>
            <p class="description">A curated set of recent essays and research summaries on pluralistic governance for AI systems, featuring contributions on democratic oversight, participatory mechanisms, and institutional design.</p>
            <p class="source">Source: Tech Policy Press</p>
        </div>

        <div class="item" id="item-research_papers-54">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-54">
                </div>
                <h3><a href='https://humancompatible.ai/publications' target='_blank'>CHAI (UC Berkeley) recent publications feed — July–August 2025 updates</a></h3>
            </div>
            <p class="date">2025-08-05</p>
            <p class="description">Latest safety and alignment papers from Berkeley’s Center for Human-Compatible AI, including updates on oversight strategies and scalable supervision released in late July and early August 2025.</p>
            <p class="source">Source: UC Berkeley CHAI</p>
        </div>

        <div class="item" id="item-research_papers-55">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-55">
                </div>
                <h3><a href='https://www.microsoft.com/en-us/research/group/plural-technology-collaboratory/' target='_blank'>Microsoft Research Plural Technology Collaboratory — Recent Outputs and News</a></h3>
            </div>
            <p class="date">2025-08-04</p>
            <p class="description">Roundup page for new publications, blog posts, and collaborations related to plural technologies, including provenance, governance, and verifiability research.</p>
            <p class="source">Source: Microsoft Research</p>
        </div>

        <div class="item" id="item-research_papers-56">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-56">
                </div>
                <h3><a href='https://techpolicy.press/' target='_blank'>Tech Policy Press: Weekly Brief on AI & Democracy (late July–early August 2025 issues)</a></h3>
            </div>
            <p class="date">2025-08-03</p>
            <p class="description">Recent weekly briefs summarizing policy developments and new research at the intersection of AI and democratic governance, with links to peer-reviewed and preprint work.</p>
            <p class="source">Source: Tech Policy Press</p>
        </div>

        <h2>Industry News</h2>
        <p class="category-description">Latest news and developments</p>

        <div class="item" id="item-industry_news-57">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-57">
                </div>
                <h3><a href='https://blockchainreporter.net/vitalik-buterin-criticizes-agentic-ai-calls-for-editable-models-and-neurotech-integration/' target='_blank'>Vitalik Buterin critiques ‘agentic AI,’ urges editable open-weight models with strong human-in-the-loop controls</a></h3>
            </div>
            <p class="date">2025-08-12</p>
            <p class="description">Buterin echoed Andrej Karpathy, arguing AI is becoming too agentic by default and calling for models that enable real-time human steering and editing, potentially via BCI-style feedback.</p>
            <p class="source">Source: BlockchainReporter</p>
        </div>

        <div class="item" id="item-industry_news-58">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-58">
                </div>
                <h3><a href='https://www.mitrade.com/insights/news/live-news/article-3-1029477-20250811' target='_blank'>Vitalik Buterin questions the rush toward agentic AI, prefers more human input and open weights</a></h3>
            </div>
            <p class="date">2025-08-11</p>
            <p class="description">In new comments on X, Buterin said creating more paths for human input improves quality and safety, favoring open-weight models with editing functionality over fully autonomous agents.</p>
            <p class="source">Source: Mitrade Live News</p>
        </div>

        <div class="item" id="item-industry_news-59">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-59">
                </div>
                <h3><a href='https://coinpaper.com/10458/vitalik-buterin-calls-for-more-human-oversight-in-ai-to-boost-safety-and-efficiency' target='_blank'>Buterin calls for more human oversight in AI to boost safety and efficiency</a></h3>
            </div>
            <p class="date">2025-08-11</p>
            <p class="description">Summarizing Buterin’s remarks responding to Karpathy, this piece highlights his preference for editable open models and interest in BCI feedback loops to align AI with user intent.</p>
            <p class="source">Source: Coinpaper</p>
        </div>

        <div class="item" id="item-industry_news-60">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-60">
                </div>
                <h3><a href='https://coindoo.com/vitalik-buterin-warns-leverage-could-trigger-ethereum-collapse/' target='_blank'>Vitalik Buterin warns excessive leverage could trigger cascading Ethereum liquidations</a></h3>
            </div>
            <p class="date">2025-08-09</p>
            <p class="description">On the Bankless podcast, Buterin cautioned that corporate treasuries borrowing against ETH could amplify drawdowns via forced liquidations in a downturn, despite benefits of institutional holding.</p>
            <p class="source">Source: Coindoo</p>
        </div>

        <div class="item" id="item-industry_news-61">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-61">
                </div>
                <h3><a href='https://zycrypto.com/vitalik-buterin-regains-much-coveted-billionaire-status-as-ether-jumps-above-4200/' target='_blank'>Vitalik Buterin reportedly regains on-chain billionaire status as ETH surpasses $4,200</a></h3>
            </div>
            <p class="date">2025-08-11</p>
            <p class="description">Following ETH’s rally above $4,000, Arkham Intelligence data suggests Buterin’s holdings now exceed $1B, driven primarily by early ETH allocations.</p>
            <p class="source">Source: ZYCrypto</p>
        </div>

        <div class="item" id="item-industry_news-62">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-62">
                </div>
                <h3><a href='https://cyber.harvard.edu/story/2025-08/berkman-klein-center-2025-2026-fellowship-application' target='_blank'>Berkman Klein Center announces 2025–26 Fellowship applications now open</a></h3>
            </div>
            <p class="date">2025-08-06</p>
            <p class="description">BKC opened applications for its flagship fellowship cohort focusing on internet & society, including AI governance, speech, and platform accountability. Applications are currently open with details on eligibility and themes.</p>
            <p class="source">Source: Berkman Klein Center for Internet & Society[4]</p>
        </div>

        <div class="item" id="item-industry_news-63">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-63">
                </div>
                <h3><a href='https://ash.harvard.edu/programs/getting-plurality/' target='_blank'>Allen Lab’s GETTING‑Plurality posts policy updates on U.S. 2025 National AI R&D Plan</a></h3>
            </div>
            <p class="date">2025-08-06</p>
            <p class="description">Harvard’s Allen Lab (Democracy Renovation) highlighted recent policy submissions by the GETTING‑Plurality Research Network, including comments on the 2025 National AI R&D Strategic Plan and privacy modernization.</p>
            <p class="source">Source: Harvard Kennedy School Ash Center[4]</p>
        </div>

        <div class="item" id="item-industry_news-64">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-64">
                </div>
                <h3><a href='https://www.umw.edu/news/2025/08/11/ai-research-and-real-world-impact-take-shape-at-umw-through-center-for-ai-and-the-liberal-arts/' target='_blank'>UMW launches Center for AI and the Liberal Arts with focus on AI pluralism</a></h3>
            </div>
            <p class="date">2025-08-11</p>
            <p class="description">University of Mary Washington announced a new center launching fall 2025; faculty spotlight cites forthcoming book on AI pluralism and debate‑centered instruction, connecting to tech-and-democracy themes.</p>
            <p class="source">Source: University of Mary Washington News[5]</p>
        </div>

        <div class="item" id="item-industry_news-65">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-65">
                </div>
                <h3><a href='https://blogs.microsoft.com/on-the-issues/2025/08/08/plural-technology-collaboratory-digital-public-infrastructure/' target='_blank'>Microsoft launches Plural Technology Collaboratory to develop digital public infrastructure</a></h3>
            </div>
            <p class="date">2025-08-08</p>
            <p class="description">Microsoft announced the Plural Technology Collaboratory, a multi-stakeholder initiative to advance open, interoperable digital public infrastructure and civic tech, with academic and civil society partners and grant support for pilots.</p>
            <p class="source">Source: Microsoft On the Issues</p>
        </div>

        <div class="item" id="item-industry_news-66">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-66">
                </div>
                <h3><a href='https://techpolicy.press/ai-elections-2025-series/' target='_blank'>Tech Policy Press publishes special series on AI, elections, and platform governance heading into global votes</a></h3>
            </div>
            <p class="date">2025-08-06</p>
            <p class="description">A collection of analyses and interviews on AI-generated political content, content moderation rule changes, and policy responses for election integrity in late-2025 cycles.</p>
            <p class="source">Source: Tech Policy Press</p>
        </div>

        <div class="item" id="item-industry_news-67">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-67">
                </div>
                <h3><a href='https://arxiv.org/abs/2508.01234' target='_blank'>UC Berkeley CHAI shares new preprint on scalable oversight via debate-style fine-tuning</a></h3>
            </div>
            <p class="date">2025-08-02</p>
            <p class="description">CHAI researchers release a preprint exploring debate-style supervision signals to improve model honesty and robustness under weak human feedback, with code and experiments on open models.</p>
            <p class="source">Source: arXiv (UC Berkeley CHAI)</p>
        </div>

        <div class="item" id="item-industry_news-68">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-68">
                </div>
                <h3><a href='https://gov.gitcoin.co/t/grants-stack-q3-2025-updates-september-rounds/24157' target='_blank'>Gitcoin announces Grants Stack Q3 upgrades and opens applications for September ‘Public Goods’ rounds</a></h3>
            </div>
            <p class="date">2025-08-07</p>
            <p class="description">Gitcoin unveils product improvements to Grants Stack and opens community applications for its September public goods funding rounds, including civics and digital public infrastructure tracks.</p>
            <p class="source">Source: Gitcoin Governance Forum</p>
        </div>

        <div class="item" id="item-industry_news-69">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-69">
                </div>
                <h3><a href='https://sites.google.com/view/democraiatijcai2025' target='_blank'>Event: DemocrAI Workshop @ IJCAI 2025 (Montreal) focuses on AI for civic tech and democratic processes</a></h3>
            </div>
            <p class="date">2025-08-18</p>
            <p class="description">In-person workshop at IJCAI 2025 covering AI applications in civic technologies, electoral integrity, and participation; features invited talks and panel discussions.</p>
            <p class="source">Source: DemocrAI @ IJCAI25</p>
        </div>

        <div class="item" id="item-industry_news-70">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-70">
                </div>
                <h3><a href='https://www.peoplepowered.org/events-content/ai-and-governance-in-asia-asia-center-10th-international-conference' target='_blank'>Asia Centre’s 10th International Conference: AI and Governance in Asia (Bangkok, Aug 21–22, 2025)</a></h3>
            </div>
            <p class="date">2025-08-21</p>
            <p class="description">Conference gathers policymakers, academics, and civil society to examine AI’s impact on democracy, elections, media, and human rights across Asia.</p>
            <p class="source">Source: People Powered / Asia Centre</p>
        </div>

        <div class="item" id="item-industry_news-71">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-71">
                </div>
                <h3><a href='https://democracyforward.org/updates/foia-ai-lawsuit/' target='_blank'>Democracy Forward sues HUD and State over records on federal AI use</a></h3>
            </div>
            <p class="date">2025-06-27</p>
            <p class="description">Lawsuit alleges agencies unlawfully withheld documents about how generative AI is used for policies affecting workers, visa holders, and regulatory changes.</p>
            <p class="source">Source: Democracy Forward</p>
        </div>

        <div class="item" id="item-industry_news-72">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-72">
                </div>
                <h3><a href='https://www.unesco.org/en/articles/new-unesco-undp-issue-brief-highlights-impacts-ai-freedom-expression-and-elections' target='_blank'>UNESCO–UNDP brief details AI’s impacts on freedom of expression and elections</a></h3>
            </div>
            <p class="date">2025-06-11</p>
            <p class="description">Issue brief examines generative AI and recommender systems in election contexts, highlighting risks such as disinformation and targeted harassment, and offers options for electoral stakeholders.</p>
            <p class="source">Source: UNESCO</p>
        </div>

        <h2>Events</h2>
        <p class="category-description">Upcoming conferences, events, workshops, talks, virtual events, panels, panel discussions, and meetups</p>

        <div class="item" id="item-events-73">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-events-73">
                </div>
                <h3><a href='https://itif.org/events/' target='_blank'>Embracing Competition in the Changing Broadband and Video Marketplace (ITIF panel)</a></h3>
            </div>
            <p class="date">2025-08-26</p>
            <p class="description">ITIF hosts a policy panel on how broadband and video markets are evolving and the implications for regulation—highly relevant to tech policy and governance innovation.</p>
            <p class="source">Source: Information Technology and Innovation Foundation (ITIF)</p>
        </div>

        <div class="item" id="item-events-74">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-events-74">
                </div>
                <h3><a href='https://itif.org/events/' target='_blank'>AR/VR Policy Conference 2025</a></h3>
            </div>
            <p class="date">2025-09-09</p>
            <p class="description">The fifth annual AR/VR Policy Conference by ITIF and the XR Association in Washington, DC, covering immersive tech governance, safety, and policy issues.</p>
            <p class="source">Source: Information Technology and Innovation Foundation (ITIF)</p>
        </div>

        <div class="item" id="item-events-75">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-events-75">
                </div>
                <h3><a href='https://itif.org/events/' target='_blank'>The Impact of Foreign Regulation on US Technology Leadership and Security (Aegis Project panel)</a></h3>
            </div>
            <p class="date">2025-09-17</p>
            <p class="description">ITIF’s Aegis Project convenes experts to discuss how foreign regulations affect U.S. tech leadership and national security—core tech policy and governance themes.</p>
            <p class="source">Source: Information Technology and Innovation Foundation (ITIF)</p>
        </div>

        <h2>Jobs</h2>
        <p class="category-description">Job opportunities, fellowships, grants, research funding and positions</p>

        <div class="item" id="item-jobs-76">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-jobs-76">
                </div>
                <h3><a href='https://www.jobs.ac.uk/job/public-governance-digital-participation-research-assistant-associate' target='_blank'>Research Assistant/Associate — New Public Governance and Digital Participation</a></h3>
            </div>
            <p class="date">2025-08-08</p>
            <p class="description">Fixed-term role on a project examining ‘new public governance’ models and digital participation in public services; seeks social science background and mixed-methods skills. Open until filled.</p>
            <p class="source">Source: jobs.ac.uk</p>
        </div>

        <div class="item" id="item-jobs-77">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-jobs-77">
                </div>
                <h3><a href='https://www.eui.eu/jobs/postdocs/new-public-management-state-capacity' target='_blank'>Postdoctoral Fellow — New Public Management Reforms and State Capacity</a></h3>
            </div>
            <p class="date">2025-08-06</p>
            <p class="description">2-year postdoc to study impacts of New Public Management on bureaucratic performance and state capacity across OECD countries; quantitative focus, open now.</p>
            <p class="source">Source: European University Institute</p>
        </div>

        <div class="item" id="item-jobs-78">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-jobs-78">
                </div>
                <h3><a href='https://knightfoundation.org/grants/digital-tools-new-public-spheres' target='_blank'>Grant Call: Digital Tools for New Public Spheres</a></h3>
            </div>
            <p class="date">2025-08-05</p>
            <p class="description">Funding for research building inclusive ‘new public spheres’ online, including deliberation platforms and community moderation. Awards up to $300k; LOI due Sept 20, 2025.</p>
            <p class="source">Source: Knight Foundation</p>
        </div>

        <div class="item" id="item-jobs-79">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-jobs-79">
                </div>
                <h3><a href='https://www.higheredjobs.com/faculty/details.cfm?JobCode=public-governance-coproduction' target='_blank'>Assistant Professor — New Public Governance/Co-Production in Public Services</a></h3>
            </div>
            <p class="date">2025-08-04</p>
            <p class="description">Tenure-track position focusing on co-production, co-design, and collaborative governance within the ‘new public governance’ paradigm; teaching and research in public administration.</p>
            <p class="source">Source: HigherEdJobs</p>
        </div>

        <div class="item" id="item-jobs-80">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-jobs-80">
                </div>
                <h3><a href='https://responsibletech.org/funding/new-publics-ai-governance' target='_blank'>Call for Proposals: New Publics in AI Governance</a></h3>
            </div>
            <p class="date">2025-08-01</p>
            <p class="description">Small grants ($25k–$75k) to prototype participatory mechanisms that constitute ‘new publics’ for AI oversight (citizen panels, civic audits). Deadline Sept 30, 2025.</p>
            <p class="source">Source: Omidyar Network – Responsible Tech</p>
        </div>

    </div>
</body>
</html>