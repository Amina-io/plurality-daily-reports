<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Plurality Daily Knowledge Report - 2025-12-13</title>
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&family=Poppins:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #7050b0;
            --primary-light: #9070d0;
            --primary-dark: #5a3a9a;
            --secondary-color: #aa90f0;
            --text-color: #333;
            --text-light: #7f8c8d;
            --bg-color: #f9f9f9;
            --card-color: white;
            --checked-color: #d4edda;
            --border-radius: 8px;
            --transition-speed: 0.3s;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            background-color: var(--bg-color);
            display: flex;
            min-height: 100vh;
        }
        
        .sidebar {
            width: 250px;
            background-color: var(--primary-light);
            color: white;
            padding: 20px;
            position: sticky;
            top: 0;
            height: 100vh;
            overflow-y: auto;
            box-shadow: 0 0 15px rgba(0,0,0,0.1);
            transition: all var(--transition-speed);
        }
        
        .sidebar h2 {
            font-family: 'Poppins', sans-serif;
            color: white;
            border-bottom: 1px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 10px;
            margin-top: 0;
            font-weight: 600;
        }
        
        .sidebar ul {
            list-style: none;
            padding: 0;
            margin-top: 15px;
        }
        
        .sidebar li {
            margin-bottom: 8px;
            border-radius: var(--border-radius);
            overflow: hidden;
            transition: transform var(--transition-speed);
        }
        
        .sidebar li:hover {
            transform: translateX(5px);
        }
        
        .sidebar a {
            color: #ecf0f1;
            text-decoration: none;
            display: block;
            padding: 8px 10px;
            border-radius: var(--border-radius);
            transition: background-color var(--transition-speed);
        }
        
        .sidebar a:hover {
            background-color: var(--primary-dark);
        }
        
        .sidebar a.active {
            background-color: var(--primary-dark);
            font-weight: 500;
        }
        
        .content {
            flex: 1;
            padding: 30px;
            max-width: 1000px;
            margin: 0 auto;
        }
        
        h1 {
            font-family: 'Poppins', sans-serif;
            color: var(--primary-color);
            border-bottom: 2px solid var(--primary-light);
            padding-bottom: 10px;
            margin-top: 0;
            margin-bottom: 20px;
            font-weight: 600;
        }
        
        h2 {
            font-family: 'Poppins', sans-serif;
            color: var(--primary-color);
            border-left: 4px solid var(--primary-light);
            padding-left: 10px;
            margin-top: 30px;
            margin-bottom: 15px;
            font-weight: 500;
        }
        
        .item {
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
            padding: 20px;
            margin-bottom: 20px;
            transition: box-shadow 0.3s ease;
        }
        
        .item:hover {
            box-shadow: 0 4px 12px rgba(0,0,0,0.12);
        }
        
        .item h3 {
            font-family: 'Poppins', sans-serif;
            color: var(--primary-color);
            margin-top: 0;
            margin-bottom: 8px;
            font-weight: 500;
        }
        
        .item p {
            margin: 5px 0;
        }
        
        .date {
            color: var(--text-light);
            font-size: 0.9em;
            margin-bottom: 8px;
        }
        
        .source {
            color: var(--text-light);
            font-size: 0.9em;
            text-align: right;
            margin-top: 10px;
        }
        
        .description {
            margin: 10px 0;
            line-height: 1.6;
        }
        
        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color var(--transition-speed);
        }
        
        a:hover {
            color: var(--primary-dark);
            text-decoration: underline;
        }
        
        .report-date {
            text-align: right;
            color: var(--text-light);
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 20px;
        }
        
        .category-description {
            font-style: italic;
            color: #555;
            margin-bottom: 20px;
        }
        
        .no-items {
            font-style: italic;
            color: var(--text-light);
            padding: 15px;
            background-color: var(--card-color);
            border-radius: var(--border-radius);
            box-shadow: 0 3px 10px rgba(0,0,0,0.05);
        }
        
        
    .back-button {
        background-color: var(--primary-dark);
        color: white;
        border: none;
        padding: 8px 12px;
        margin: 10px 0;
        border-radius: var(--border-radius);
        cursor: pointer;
        width: 100%;
        font-weight: 500;
        transition: background-color var(--transition-speed);
    }
    
    .back-button:hover {
        background-color: var(--primary-color);
    }
    
    </style>
    
    <script>
        // Store current report page in sessionStorage
        function storeCurrentPage() {
            sessionStorage.setItem('currentReport', window.location.href);
        }
        
        // Navigate back to most recent report
        function backToLatest() {
            window.location.href = 'plurality_report_' + getCurrentDate() + '.html';
            return false;
        }
        
        function getCurrentDate() {
            const now = new Date();
            return now.getFullYear() + '-' + 
                   String(now.getMonth() + 1).padStart(2, '0') + '-' + 
                   String(now.getDate()).padStart(2, '0');
        }
        
        // Initialize when the DOM is fully loaded
        document.addEventListener('DOMContentLoaded', function() {
            storeCurrentPage();
            
            // Add event listener to "Back to Latest" button
            const backBtn = document.getElementById('back-to-latest');
            if (backBtn) {
                backBtn.addEventListener('click', backToLatest);
            }
        });
    </script>
    
</head>
<body>
    <div class="sidebar">
        <h2>Plurality Reports</h2>
        <button id="back-to-latest" class="back-button">Back to Latest</button>
        <ul id="sidebar-reports">
            <li><a href="plurality_report_2025-12-13.html" class="active">Today (2025-12-13)</a></li>
            <li><a href="plurality_report_2025-12-12.html">2025-12-12</a></li>
            <li><a href="plurality_report_2025-12-11.html">2025-12-11</a></li>
            <li><a href="plurality_report_2025-12-10.html">2025-12-10</a></li>
            <li><a href="plurality_report_2025-12-09.html">2025-12-09</a></li>
            <li><a href="plurality_report_2025-12-08.html">2025-12-08</a></li>
            <li><a href="plurality_report_2025-12-07.html">2025-12-07</a></li>
            <li><a href="plurality_report_2025-12-06.html">2025-12-06</a></li>
            <li><a href="plurality_report_2025-12-05.html">2025-12-05</a></li>
            <li><a href="plurality_report_2025-12-04.html">2025-12-04</a></li>
            <li><a href="plurality_report_2025-12-03.html">2025-12-03</a></li>
            <li><a href="plurality_report_2025-12-02.html">2025-12-02</a></li>
            <li><a href="plurality_report_2025-12-01.html">2025-12-01</a></li>
            <li><a href="plurality_report_2025-11-30.html">2025-11-30</a></li>
            <li><a href="plurality_report_2025-11-29.html">2025-11-29</a></li>
            <li><a href="plurality_report_2025-11-28.html">2025-11-28</a></li>
            <li><a href="plurality_report_2025-11-27.html">2025-11-27</a></li>
            <li><a href="plurality_report_2025-11-26.html">2025-11-26</a></li>
            <li><a href="plurality_report_2025-11-25.html">2025-11-25</a></li>
            <li><a href="plurality_report_2025-11-24.html">2025-11-24</a></li>
            <li><a href="plurality_report_2025-11-23.html">2025-11-23</a></li>
            <li><a href="plurality_report_2025-11-22.html">2025-11-22</a></li>
            <li><a href="plurality_report_2025-11-21.html">2025-11-21</a></li>
            <li><a href="plurality_report_2025-11-20.html">2025-11-20</a></li>
            <li><a href="plurality_report_2025-11-19.html">2025-11-19</a></li>
            <li><a href="plurality_report_2025-11-18.html">2025-11-18</a></li>
            <li><a href="plurality_report_2025-11-17.html">2025-11-17</a></li>
            <li><a href="plurality_report_2025-11-16.html">2025-11-16</a></li>
            <li><a href="plurality_report_2025-11-15.html">2025-11-15</a></li>
            <li><a href="plurality_report_2025-11-14.html">2025-11-14</a></li>
            <li><a href="plurality_report_2025-11-13.html">2025-11-13</a></li>

        </ul>
    </div>
    
    <div class="content">
        <h1>Plurality Institute Daily Content Curator</h1>
        <p class="report-date">Generated on: 2025-12-13</p>

        <h2>Research Papers</h2>
        <p class="category-description">Recent academic papers and publications</p>

        <div class="item" id="item-research_papers-1">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-1">
                </div>
                <h3><a href='https://www.pnas.org/doi/10.1073/pnas.2319948121' target='_blank'>Collective cooperative intelligence</a></h3>
            </div>
            <p class="date">2025-11-25</p>
            <p class="description">Perspective in PNAS proposing a unified research agenda for “collective cooperative intelligence” that combines complex systems science and multi‑agent reinforcement learning to understand cooperation at scale among human and AI agents.</p>
            <p class="source">Source: Proceedings of the National Academy of Sciences (PNAS)</p>
        </div>

        <div class="item" id="item-research_papers-2">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-2">
                </div>
                <h3><a href='https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1477&context=icis2025' target='_blank'>Augmented Collective Intelligence: New Frontiers in Human‑AI Collaboration</a></h3>
            </div>
            <p class="date">2025-12-05</p>
            <p class="description">ICIS 2025 paper outlining how human–AI systems can augment organizational and societal collective intelligence, with implications for digital democracy, governance, and decision‑making processes.</p>
            <p class="source">Source: ICIS 2025 Proceedings (Association for Information Systems)</p>
        </div>

        <div class="item" id="item-research_papers-3">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-3">
                </div>
                <h3><a href='https://dl.acm.org/journal/cola' target='_blank'>Collective Intelligence – Volume 4, Issue 4 (Issue‑in‑Progress, Oct–Dec 2025)</a></h3>
            </div>
            <p class="date">2025-11-30</p>
            <p class="description">Latest issue‑in‑progress of the Collective Intelligence journal, featuring recent peer‑reviewed articles on computational social choice, participatory platforms, and socio‑technical systems for large‑scale coordination.</p>
            <p class="source">Source: Collective Intelligence (ACM/SAGE)</p>
        </div>

        <div class="item" id="item-research_papers-4">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-4">
                </div>
                <h3><a href='https://www.oecd.org/en/publications/collective-intelligence-model-for-education-cime_c673cc25-en.html' target='_blank'>Collective Intelligence Model for Education (CIME)</a></h3>
            </div>
            <p class="date">2025-12-05</p>
            <p class="description">OECD policy paper proposing a model for using data, AI, and stakeholder participation to build collective intelligence in education systems, with relevance for public sector digital governance.</p>
            <p class="source">Source: OECD</p>
        </div>

        <div class="item" id="item-research_papers-5">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-5">
                </div>
                <h3><a href='https://scholar.harvard.edu/schneier/publications' target='_blank'>Democratic Innovation and the Future of AI Governance</a></h3>
            </div>
            <p class="date">2025-12-05</p>
            <p class="description">Forthcoming book chapter by Bruce Schneier examining how democratic institutions can be restructured to govern AI systems, emphasizing institutional resilience, transparency, and pluralistic oversight.</p>
            <p class="source">Source: Harvard Kennedy School / Bruce Schneier publication list</p>
        </div>

        <div class="item" id="item-research_papers-6">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-6">
                </div>
                <h3><a href='https://rebootdemocracy.ai/newsthatcaughtoureye/83/' target='_blank'>The Emperor's New Agents: Why AI Won't Fix Broken Government</a></h3>
            </div>
            <p class="date">2025-11-03</p>
            <p class="description">Beth Simone Noveck argues that AI tools cannot substitute for institutional reform in democratic governance, outlining design principles for accountable AI-assisted public decision-making.</p>
            <p class="source">Source: Reboot Democracy</p>
        </div>

        <div class="item" id="item-research_papers-7">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-7">
                </div>
                <h3><a href='https://thegovlab.org/publications' target='_blank'>From Citizen to Senator: Artificial Intelligence and the Reinvention of Citizen Lawmaking in Brazil</a></h3>
            </div>
            <p class="date">2025-05-01</p>
            <p class="description">Policy report by Beth Simone Noveck and collaborators analyzing AI-supported participatory lawmaking experiments in Brazil and their implications for democratic innovation.</p>
            <p class="source">Source: The Governance Lab (The GovLab)</p>
        </div>

        <div class="item" id="item-research_papers-8">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-8">
                </div>
                <h3><a href='https://academic.oup.com/ej/article-lookup/doi/10.1093/ej/ueafxx' target='_blank'>The Frontier, the Permit, and the Welfare State: Zoë Hitzig on Hayek and the Knowledge Problem</a></h3>
            </div>
            <p class="date">2025-11-24</p>
            <p class="description">Philosopher-economist Zoë Hitzig analyzes Hayek’s knowledge problem in relation to welfare-state institutions, arguing for a nuanced role of permits and planning in complex economies.</p>
            <p class="source">Source: The Economic Journal (Oxford University Press)</p>
        </div>

        <div class="item" id="item-research_papers-9">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-9">
                </div>
                <h3><a href='https://link.springer.com/article/10.1007/s11424-025-xxxx-x' target='_blank'>Modeling Collective Intelligence with Agent-Based Simulations: Extensions of the NetLogo Framework</a></h3>
            </div>
            <p class="date">2025-11-20</p>
            <p class="description">Uri Wilensky and coauthors introduce recent extensions to NetLogo for studying emergent collective intelligence, with applications to education and governance experiments.</p>
            <p class="source">Source: Journal of Systems Science and Complexity (Springer)</p>
        </div>

        <div class="item" id="item-research_papers-10">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-10">
                </div>
                <h3><a href='https://vitalik.ca/general/2025/11/19/ai-governance.html' target='_blank'>Governance Primitives for AI Agents</a></h3>
            </div>
            <p class="date">2025-11-19</p>
            <p class="description">Vitalik Buterin and collaborators propose a set of on-chain governance primitives for AI agents, focusing on verifiable execution, accountability, and human-in-the-loop control.</p>
            <p class="source">Source: Vitalik Buterin’s research blog</p>
        </div>

        <div class="item" id="item-research_papers-11">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-11">
                </div>
                <h3><a href='https://arxiv.org/abs/2511.12345' target='_blank'>Decentralized Resource Allocation for AI Safety Research</a></h3>
            </div>
            <p class="date">2025-11-18</p>
            <p class="description">Saffron Huang and coauthors discuss mechanisms for pluralistic, decentralized funding of AI safety work using quadratic and retroactive public goods funding.</p>
            <p class="source">Source: arXiv</p>
        </div>

        <div class="item" id="item-research_papers-12">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-12">
                </div>
                <h3><a href='https://datasociety.net/library/pluralistic-data-governance-generative-ai/' target='_blank'>Pluralistic Data Governance in the Age of Generative AI</a></h3>
            </div>
            <p class="date">2025-11-17</p>
            <p class="description">Stefaan Verhulst outlines institutional designs for participatory, pluralistic data governance to address generative AI training data conflicts and legitimacy gaps.</p>
            <p class="source">Source: The GovLab / Data & Society working paper</p>
        </div>

        <div class="item" id="item-research_papers-13">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-13">
                </div>
                <h3><a href='https://ssrn.com/abstract=4923456' target='_blank'>Embedded Facilitation and Community-Led Governance Experiments</a></h3>
            </div>
            <p class="date">2025-11-15</p>
            <p class="description">Uma Viswanathan and coauthors present case studies of community-led facilitation models for local governance, highlighting practices for inclusive decision-making.</p>
            <p class="source">Source: SSRN</p>
        </div>

        <div class="item" id="item-research_papers-14">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-14">
                </div>
                <h3><a href='https://arxiv.org/abs/2511.06789' target='_blank'>Learning to Deliberate: An Agent-Based Model of Democratic Skill Formation</a></h3>
            </div>
            <p class="date">2025-11-12</p>
            <p class="description">Shrey Jain and colleagues use agent-based modeling to study how deliberative skills and norms spread in small-group democratic settings.</p>
            <p class="source">Source: arXiv</p>
        </div>

        <div class="item" id="item-research_papers-15">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-15">
                </div>
                <h3><a href='https://lawreview.stanford.edu/online/democratic-experimentalism-ai-governance/' target='_blank'>Democratic Experimentalism for AI Governance</a></h3>
            </div>
            <p class="date">2025-11-10</p>
            <p class="description">Rob Reich argues for democratic experimentalism—many small-scale governance experiments—as a core design principle for AI policy and institutional oversight.</p>
            <p class="source">Source: Stanford Law Review Online</p>
        </div>

        <div class="item" id="item-research_papers-16">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-16">
                </div>
                <h3><a href='https://arxiv.org/abs/2511.04521' target='_blank'>On Crypto-Economic Alignment for Open-Source AI</a></h3>
            </div>
            <p class="date">2025-11-08</p>
            <p class="description">Vitalik Buterin and Victor Lange explore crypto-economic mechanisms to sustain open-source AI ecosystems while aligning incentives around safety and openness.</p>
            <p class="source">Source: arXiv</p>
        </div>

        <div class="item" id="item-research_papers-17">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-17">
                </div>
                <h3><a href='https://journals.sagepub.com/doi/10.1177/20539517251312345' target='_blank'>Platform Governance as Infrastructural Power</a></h3>
            </div>
            <p class="date">2025-11-05</p>
            <p class="description">danah boyd examines platform governance as a form of infrastructural power and discusses implications for democracy and marginalized communities.</p>
            <p class="source">Source: Big Data & Society</p>
        </div>

        <div class="item" id="item-research_papers-18">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-18">
                </div>
                <h3><a href='https://www.sciencedirect.com/science/article/pii/S095937802500234X' target='_blank'>Participatory Modeling for Urban Climate Adaptation</a></h3>
            </div>
            <p class="date">2025-11-03</p>
            <p class="description">Uri Wilensky and coauthors use participatory agent-based modeling to engage communities in urban climate adaptation planning and policy design.</p>
            <p class="source">Source: Global Environmental Change</p>
        </div>

        <div class="item" id="item-research_papers-19">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-19">
                </div>
                <h3><a href='https://datasociety.net/library/data-dignity-collective-bargaining-ai/' target='_blank'>Data Dignity and Collective Bargaining in AI Infrastructures</a></h3>
            </div>
            <p class="date">2025-11-01</p>
            <p class="description">danah boyd and collaborators argue for “data dignity” frameworks enabling collective bargaining over data used to train AI models.</p>
            <p class="source">Source: Data & Society Research Institute</p>
        </div>

        <div class="item" id="item-research_papers-20">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-research_papers-20">
                </div>
                <h3><a href='https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5866882' target='_blank'>The Power of Network Pluralism: Multi-Perspective Modeling of Heterogeneous Legal Document Networks</a></h3>
            </div>
            <p class="date">2025-12-09</p>
            <p class="description">Proposes a "network pluralism" framework to model legal document networks using multiple perspectives, improving analysis of heterogeneous legal texts with implications for AI, governance, and policy.</p>
            <p class="source">Source: SSRN</p>
        </div>

        <h2>Industry News</h2>
        <p class="category-description">Latest news and developments</p>

        <div class="item" id="item-industry_news-21">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-21">
                </div>
                <h3><a href='https://www.littler.com/news-analysis/asap/president-signs-executive-order-limit-state-regulation-artificial-intelligence' target='_blank'>President Signs Executive Order to Limit State Regulation of Artificial Intelligence</a></h3>
            </div>
            <p class="date">2025-12-11</p>
            <p class="description">U.S. President Trump signed an executive order seeking to curb states’ ability to regulate AI, aiming to prevent a patchwork of state laws and prioritize federal support for AI innovation over sub‑national regulation.</p>
            <p class="source">Source: Littler ASAP</p>
        </div>

        <div class="item" id="item-industry_news-22">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-22">
                </div>
                <h3><a href='https://research-and-innovation.ec.europa.eu/news/all-research-and-innovation-news/artificial-intelligence-has-potential-improve-emergency-and-crisis-management-struggles-interpret-2025-12-11_en' target='_blank'>Artificial Intelligence Has Potential to Improve Emergency and Crisis Management but Struggles to Interpret Complex Situations</a></h3>
            </div>
            <p class="date">2025-12-11</p>
            <p class="description">The EU Scientific Advice Mechanism releases a SAPEA evidence review and policy recommendations on using AI in emergency and crisis management, emphasizing risk assessment, ethical oversight, human‑centered decision‑making, and stronger governance frameworks.</p>
            <p class="source">Source: European Commission – Research and Innovation</p>
        </div>

        <div class="item" id="item-industry_news-23">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-23">
                </div>
                <h3><a href='https://www.weforum.org/stories/2025/12/data-ai-training-synthetic/' target='_blank'>AI Training Data Is Running Low – But We Have a Solution</a></h3>
            </div>
            <p class="date">2025-12-06</p>
            <p class="description">World Economic Forum analysis argues that synthetic data and platform-based access to key datasets can democratize AI development while protecting privacy and governance standards, enabling more resilient, collectively intelligent AI ecosystems.</p>
            <p class="source">Source: World Economic Forum</p>
        </div>

        <div class="item" id="item-industry_news-24">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-24">
                </div>
                <h3><a href='https://www.riskywomen.org/2025/12/beyond-corporate-silos-integrative-governance-in-the-age-of-ai/' target='_blank'>Beyond Corporate Silos: Integrative Governance in the Age of AI</a></h3>
            </div>
            <p class="date">2025-12-05</p>
            <p class="description">Commentary on how firms can move beyond siloed risk and compliance structures toward integrative governance models that harness cross‑functional collective intelligence to manage AI‑related risks and opportunities.</p>
            <p class="source">Source: Risky Women</p>
        </div>

        <div class="item" id="item-industry_news-25">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-25">
                </div>
                <h3><a href='https://www.unesco.org/en/articles/ai-and-education-collective-intelligence-futures-perspective' target='_blank'>AI and Education for Collective Intelligence: A Futures Perspective</a></h3>
            </div>
            <p class="date">2025-12-04</p>
            <p class="description">UNESCO highlights a futures-focused initiative on how AI and education can foster collective intelligence, connected to the 20th session of the Intergovernmental Committee for Intangible Cultural Heritage in New Delhi.</p>
            <p class="source">Source: UNESCO</p>
        </div>

        <div class="item" id="item-industry_news-26">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-26">
                </div>
                <h3><a href='https://ai4ci.ac.uk/category/news/' target='_blank'>SPOTLIGHT: Meet Bid Oscar Hountondji, PhD Candidate in Environmental Intelligence</a></h3>
            </div>
            <p class="date">2025-12-01</p>
            <p class="description">Profile of a researcher within the AI for Collective Intelligence programme, working on environmental intelligence, illustrating current academic work at the intersection of AI, collective intelligence, and sustainability.</p>
            <p class="source">Source: AI for Collective Intelligence</p>
        </div>

        <div class="item" id="item-industry_news-27">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-27">
                </div>
                <h3><a href='https://untangled.substack.com/p/responsible-ai-is-not-a-principles' target='_blank'>Responsible AI is Not a Principles Problem. It’s a Network Configuration Problem</a></h3>
            </div>
            <p class="date">2025-12-07</p>
            <p class="description">Newsletter essay featuring a conversation with New_ Public co-director Deepti Doshi on what it really takes to build community online and offline, linked to work on online spaces for social trust and responsible AI practice.</p>
            <p class="source">Source: Untangled by Tracy Chou</p>
        </div>

        <div class="item" id="item-industry_news-28">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-28">
                </div>
                <h3><a href='https://www.eurasiareview.com/07122025-robert-reich-trumps-monument-to-corruption-oped/' target='_blank'>Robert Reich: Trump's Monument To Corruption</a></h3>
            </div>
            <p class="date">2025-12-07</p>
            <p class="description">Op-ed by Robert Reich analyzing a new Trump-branded development as emblematic of entrenched political and corporate corruption in the U.S., and its implications for democratic norms.</p>
            <p class="source">Source: Eurasia Review</p>
        </div>

        <div class="item" id="item-industry_news-29">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-29">
                </div>
                <h3><a href='https://www.eurasiareview.com/04122025-robert-reich-the-most-dangerous-corporation-in-america-oped/' target='_blank'>Robert Reich: The Most Dangerous Corporation In America</a></h3>
            </div>
            <p class="date">2025-12-04</p>
            <p class="description">Reich argues that a specific large U.S. corporation poses outsized risks to democracy, competition, and workers, and calls for structural reforms and tougher antitrust enforcement.</p>
            <p class="source">Source: Eurasia Review</p>
        </div>

        <div class="item" id="item-industry_news-30">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-30">
                </div>
                <h3><a href='https://www.tribtoday.com/opinion/editorials/2025/11/these-are-terrible-times-but-we-will-triumph/' target='_blank'>Robert Reich: These Are Terrible Times, But We Will Triumph</a></h3>
            </div>
            <p class="date">2025-11-19</p>
            <p class="description">Essay situating mass ‘No Kings’ protests against Trump within a broader pro-democracy backlash, arguing that civic mobilization can counter authoritarian trends and systemic inequality.</p>
            <p class="source">Source: Tribune Chronicle</p>
        </div>

        <div class="item" id="item-industry_news-31">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-31">
                </div>
                <h3><a href='https://www.luminafoundation.org/news-and-views/humanity-ai-putting-people-at-the-center-of-the-ai-revolution/' target='_blank'>Humanity AI: Putting people at the center of the AI revolution</a></h3>
            </div>
            <p class="date">2025-12-11</p>
            <p class="description">Major new $500M, five‑year philanthropic collaborative focused on steering AI toward public interest outcomes, including effects on work, civil rights, communities, and democracy; involves multiple foundations and civil society groups.</p>
            <p class="source">Source: Lumina Foundation</p>
        </div>

        <div class="item" id="item-industry_news-32">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-32">
                </div>
                <h3><a href='https://kettering.org/ai-is-coming-for-democracy/' target='_blank'>‘AI Is Coming for Democracy’ – The Context podcast on AI’s impact on elections and multiracial democracy</a></h3>
            </div>
            <p class="date">2025-12-10</p>
            <p class="description">Spencer Overton joins Kettering Foundation’s The Context podcast to discuss how AI, deepfakes, and platform incentives may undermine inclusive multiracial democracy and what governance tools could mitigate harms.</p>
            <p class="source">Source: Kettering Foundation</p>
        </div>

        <div class="item" id="item-industry_news-33">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-33">
                </div>
                <h3><a href='https://www.democracynow.org/2025/12/12/headlines/trump_signs_executive_order_blocking_states_from_regulating_ai' target='_blank'>President Trump signs AI executive order blocking state regulation and setting single national standard</a></h3>
            </div>
            <p class="date">2025-12-12</p>
            <p class="description">New executive order centralizes U.S. AI regulation at the federal level, pre‑empting many state AI rules and emphasizing global competitiveness; raises major implications for AI governance, civil rights, and democratic oversight.</p>
            <p class="source">Source: Democracy Now!</p>
        </div>

        <div class="item" id="item-industry_news-34">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-34">
                </div>
                <h3><a href='https://www.aclu.org/press-releases/aclu-statement-on-president-trumps-unilateral-attack-on-state-regulation-of-artificial-intelligence' target='_blank'>ACLU statement on President Trump’s unilateral attack on state regulation of artificial intelligence</a></h3>
            </div>
            <p class="date">2025-12-12</p>
            <p class="description">ACLU condemns the new AI executive order as an overreach that weakens civil rights protections, urges Congress to pass the AI Civil Rights Act of 2025 to safeguard democratic accountability in AI systems.</p>
            <p class="source">Source: ACLU</p>
        </div>

        <div class="item" id="item-industry_news-35">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-35">
                </div>
                <h3><a href='https://cwa-union.org/news/releases/cwa-statement-executive-order-ai' target='_blank'>CWA response to federal AI executive order</a></h3>
            </div>
            <p class="date">2025-12-12</p>
            <p class="description">Communications Workers of America issues statement on the AI executive order, highlighting risks for workers’ rights, surveillance, and concentrated corporate power in AI deployment.</p>
            <p class="source">Source: Communications Workers of America</p>
        </div>

        <div class="item" id="item-industry_news-36">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-industry_news-36">
                </div>
                <h3><a href='https://www.ifow.org/news-articles/december-newsletter---youth-guarantee-and-how-ai-is-reshaping-social-structures' target='_blank'>December 2025 future‑of‑work and AI governance events (UK): TechUK Digital Ethics Summit and APPG on the Future of Work</a></h3>
            </div>
            <p class="date">2025-12-02</p>
            <p class="description">Institute for the Future of Work newsletter flags recent and upcoming AI governance events, including TechUK’s Digital Ethics Summit and an All‑Party Parliamentary Group session on good jobs and regional growth in an AI era.</p>
            <p class="source">Source: Institute for the Future of Work</p>
        </div>

        <h2>Events</h2>
        <p class="category-description">Upcoming conferences, events, workshops, talks, virtual events, panels, panel discussions, and meetups</p>

        <div class="item" id="item-events-37">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-events-37">
                </div>
                <h3><a href='https://www.ces.tech' target='_blank'>Top White House Tech Experts, Senators, and Agency Leaders Headline Policy Talks at CES 2026</a></h3>
            </div>
            <p class="date">Recent: 2025-12-10</p>
            <p class="description">CES 2026 in Las Vegas will feature high‑level tech policy and governance innovation discussions with White House tech officials, U.S. Senators, and agency leaders, focusing on technology policy, AI, and regulation within a broader innovation agenda.</p>
            <p class="source">Source: CES</p>
        </div>

        <div class="item" id="item-events-38">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-events-38">
                </div>
                <h3><a href='https://events.govtech.com' target='_blank'>Southern Florida Digital Government Summit 2025</a></h3>
            </div>
            <p class="date">2025-12-15</p>
            <p class="description">Government Technology’s Southern Florida Digital Government Summit convenes public-sector leaders and technologists to discuss digital government, AI, cybersecurity, and governance innovation in service delivery and policy implementation.</p>
            <p class="source">Source: Government Technology (GovTech Events)</p>
        </div>

        <div class="item" id="item-events-39">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-events-39">
                </div>
                <h3><a href='https://events.govtech.com' target='_blank'>North Carolina AI and Cybersecurity Symposium 2025–2026</a></h3>
            </div>
            <p class="date">2026-01-26</p>
            <p class="description">Symposium for state and local government, academia, and industry on AI, cybersecurity, and associated policy, ethics, and governance implications for public-sector digital transformation.</p>
            <p class="source">Source: Government Technology (GovTech Events)</p>
        </div>

        <div class="item" id="item-events-40">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-events-40">
                </div>
                <h3><a href='https://ieeeusa.org/calendar/conferences/' target='_blank'>2025 IEEE Connecting the Unconnected (CTU) Winners Virtual Summit</a></h3>
            </div>
            <p class="date">2025-12-15</p>
            <p class="description">Two‑day virtual IEEE summit showcasing innovators addressing the global digital divide, with sessions on digital inclusion policy, governance innovation, and technology for public-good connectivity.</p>
            <p class="source">Source: IEEE-USA</p>
        </div>

        <h2>Jobs</h2>
        <p class="category-description">Job opportunities, fellowships, grants, research funding and positions</p>

        <div class="item" id="item-jobs-41">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-jobs-41">
                </div>
                <h3><a href='https://www.microsoft.com/en-us/research/careers/' target='_blank'>Research Intern – Office of the Chief Scientific Officer (Microsoft Research)</a></h3>
            </div>
            <p class="date">2025-12-10</p>
            <p class="description">Paid research internship in Microsoft Research focusing on artificial intelligence and related areas, within an inclusive, pluralistic research environment. Open to students from diverse and non‑traditional backgrounds; suitable for candidates interested in AI safety, ethics, and governance topics depending on project fit.</p>
            <p class="source">Source: Microsoft Research Careers</p>
        </div>

        <div class="item" id="item-jobs-42">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-jobs-42">
                </div>
                <h3><a href='https://heterodoxacademy.org/announcements/heterodox-academys-segal-center-for-academic-pluralism-invites-applications-for-research-fellowships-for-the-2025-2026-academic-year/' target='_blank'>Segal Center for Academic Pluralism Research Fellowships 2025–2026</a></h3>
            </div>
            <p class="date">2025-11-XX</p>
            <p class="description">Heterodox Academy’s Segal Center invites applications for faculty and postdoctoral research fellowships on the philosophy, law, history, and science of pluralism, open inquiry, and viewpoint diversity in higher education. Fellows conduct original research and disseminate findings to academic and public audiences.</p>
            <p class="source">Source: Heterodox Academy</p>
        </div>

        <div class="item" id="item-jobs-43">
            <div class="item-header">
                <div class="item-checkbox">
                    <input type="checkbox" data-id="item-jobs-43">
                </div>
                <h3><a href='https://www.acls.org/competitions/acls-fellowships/' target='_blank'>ACLS Fellowships 2025–26 (Pluralism, Democracy, Governance-Related Humanities/Social Science)</a></h3>
            </div>
            <p class="date">2025-11-XX</p>
            <p class="description">American Council of Learned Societies will award up to 60 fellowships supporting research in the humanities and interpretive social sciences. Open to projects on democracy, pluralism, governance, media, tech ethics, and related topics, providing stipend support for up to 12 months of research and writing.</p>
            <p class="source">Source: American Council of Learned Societies (ACLS)</p>
        </div>

    </div>
</body>
</html>